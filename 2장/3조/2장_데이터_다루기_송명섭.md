I. Scaler

실습용으로 준비된 데이터는 잘 가공되어 있지만, 실전 데이터는 누락된 값 또는 불균일한 형태일 수 있으므로 그대로 사용 시 제대로 된 결과를 얻기 난해함. -> 데이터 전처리의 필요성

AI 모델 구현 시, 데이터 전처리 과정에서 필요한 것 중 하나는 "스케일 조정",
이를 하는 것이 바로 "scaler"
-특성의 단위나 범위가 다른 매우 많은 데이터를 설정한 기준 내에서 평가 가능

scikitlearn에서 제공하는 스케일러

1. StandardScaler
- 평균 0, 분산 1로 조정

Q. standard는 만능인가? 
A.  NO. outlier에 취약함.
-scaler의 의의는 데이터의 수치화
-데이터 분포의 시각화가 필요한데, 데이터가 표준 정규분포를 따를 때 전제하에는 효율적이나,
특정 이상값 존재 시 사용하기 난해하다. 혹은 개형이 치우친 경우
(왜도의 절댓값이 큰 경우, 여기서 왜도는 분포의 비대칭도를 의미하며, 정규분포처럼 대칭인 분포는 0의 값)

아래는 자주 쓰이는 다른 스케일러들

2. MinMaxScaler
- 각 특성을 주어진 범위 내의 값으로 변환
- ex) [0,1] : 최댓값을 1, 최솟값을 0으로 범위 조정

3. RobustScaler
- 평균과 분산을 사용한 StandardScaler과 달리 중앙값과 사분위값(IQR)을 사용
- 이상치의 영향 최소화

그 외 : log, sqrt

특정 스케일러가 만능이다! (X)
데이터의 특성에 따라 적합한 방식으로 선택하고, 왜 쓸 건지 이유를 필히 알도록.


II. 결정계수(R-Squre, R^2)

R square
- '독립변수가 종속변수를 얼만큼 설명해 주는가?' 에 대한 지표
- 계산된 예측값이 실제 y값을 얼마나 설명하는지를 나타냄, 모형의 설명력 
-  R square = 1- SSE/SSR
- 설명 지표이나 값 자체는 특정 기준이 없다.
- 보통 0과 1 사이의 범위이나 코드 구현 시 특정한 경우에 음수가 나올 수도 있다.
(제대로 설명하지 못하며, 해당 모델이 기준 모델보다 예측을 못 함) 
- 1의 값을 가진다는 것은 주어진 데이터를 잘 설명한다는 것이나, 과적합 가능성 有
즉, 새로운 데이터에 대한 일반화가 난해할 수 있음

adjusted R square
- 독립변수의 유의 여부와 별개로 그 수가 늘어나면 결정계수가 높아지는 
기존 R squre의 단점을 보완, 즉 독립변수의 개수를 고려


III. bias  VS  var

(하단은 예전에 써둔 것인데 연결되는 내용이면서 상기시킬 겸 추가로 적은 입문 개념)

가로축 - 입력,x,특징(피처)
세로축 - 목푯값, y

ex) 공부시간 x와 성적 y의 경우 특징이 하나이나, 보통 2개 이상의 특징으로 구성된 특징 벡터 형태
(tmi. 그래서 스칼라 기호 x가 아닌 벡터 기호 x를 씀.)

(특징벡터, 목푯값) 쌍은 기계학습에 주어지는 데이터 : 훈련집합(학습집합)
훈련집합의 요소 : 샘플

훈련집합: X = {x1, x2, ... ,xn} , Y = {y1, y2, ... , yn}

직선형 모델은 y= wx +b 로 표현됨.(w,b는 매개변수)

학습(훈련) : 성능이 개선되며 최적의 상태에 도달하는 작업
테스트(test) : 훈련집합에 없는 '새로운' 샘플에 대한 목푯값을 예측하는 과정



다차원의 특징 공간

d차원의 데이터 : x = (x1,x2,...xd)^T
54877개의 단어의 빈도 파악 -> 544877차원

특징 공간 변환 - 분류에 유리하도록 특징 공간 변환 가능
차원이 증가한다고 알고리즘이 바뀌어야 하진 않음.

데이터베이스 = 훈련집합 + 테스트집합


고차원의 데이터 가시화 : 차원 축소

선형회귀 - 직선 모델을 사용하여 회귀 문제를 해결하는 기계학습 알고리즘 
직선 모델이므로 추정할 매개변수는 w,b 2개이고,  묶어서 다음과 같이 표현함.
θ = (w,b)^T

at first, we don't know the optimized θ -> 난수 생성 : θ1
 θ1을 개선하여  θ2로, 또 개선하여  θ3, ..., 최종적으로 최적의  θ에 도달
이때 직선을 움직이는 일종의 원동력이 필요, 목적함수(비용함수)

(예측함수의 출력) - (목푯값) -> 오차

목적함수의 값이 준다는 것은 오차자 개선된다는 것

최적의  θ = argmin J( θ) -> 기계학습의 역할
목적함수 값이 작아지는 방향을 찾아 매개변수 값 조정 반복

p.43 분석적 방법 vs 수치적 방법

과소적합, 과대적합
선형 모델의 한계? 과소적합 발생 시, 고차원의 다항식을 사용하자.
y = wx + w0
y = w12x^12 + w11x^11 + ... +  w2x^2 + w1x + w0 (12차원. 1차 미분 시 극점이 최대 11개인 대용량 모델)

 교재의 선형 다항식과 12차원 다항식 비교 시, 후자의 비선형이 완벽에 가깝게 '학습'을 함.
하지만 (학습이 아닌)'예측'을 해야 한다면 평가가 다름. 예측 값은 합리적인 범위 내에서 이루어져야 함.
-> 부적절한 이유는 용량이 매우 크기 때문이다.
-> 데이터 분포에 비해 너무나 대용량, 미세 잡음까지 반영해버림.(overfitting, low bias, high var)


기계학습의 목표는 훈련집합에 없는 새로운 샘플을 정확히 예측함에 있다.
다시 말해, 테스트 집합에 대한 고성능을 보장하는 프로그램을 만드는 것(일반화)

일반화를 위해 알아둘 것 -> bias, var(이 둘은 trade-off 관계)
Bias
-치우친 정도/ 출력과 정답 간 차이의 정도(머신러닝) 
Var
-퍼져있는 정도 /모델 예측의 가변성(머신러닝) 


Overfitting(상단의 고차원 방정식 연상)
- low bias, high var
Underfitting(저차원의 단순한 모델 복잡도, 적은 feature)
- high bias, low var
- feature를 더 많이 반영하여 var 높이기(활용 모델: kNN, SVM,...)


훈련집합으로 모델 학습, 테스트집합으로 일반화 능력 측정
-> 그렇다면, 좋은 모델을 찾기 위해 여러 모델 간 비교를 하는 방법은?

모델 선택 알고리즘 - 검증집합, 교차검증, 부트스트랩


IV. Validation

먼저 이해할 것은 '데이터셋의 분리', 왜 데이터를 train, test 외에 valid까지 구분하는가? 

예측할 데이터를 모델에 적용하기 전에 모델 학습이 선행되어야 함. 모델 구현에 필요한 건 학습 데이터
모델을 평가하는 데 쓰이는 건 테스트 데이터
모델을 '검증'하는 데 쓰이는 게 validation set(검증을 통해 모델 성능 개선. 파라미터 튜닝도 한 과정)

평가와 검증을 분리해서 생각할 것
- 모델 검증에 쓰인 데이터를 모델 평가에 사용 시 높은 점수를 얻는 것은 trivial(지난 시간의 Data Leakage 연상)
- 계수 조정은 train에서, val은 변경 없이 검증만

Then, how to make the Validation Set?
1. 전체 데이터셋을 train과 test로 구분(보통 7:3 or 8:2가 보편적)
2. train set을 다시 train과 validation으로 구분

Warning) 전체 데이터가 너무 적다면 train_test_split과 ramdom_state의 매개변수를 조금만 조정해도 성능 평가
차이가 큼. 이때 교차검증 활용 가능

관련 메소드 : train_test_split()

train과 test로 분리할 때, train을 train과 test로 분리할 때의 두 가지 경우 모두 사용
해당 메소드 내에 parameter가 많은데, 이 중에서

random_state
- 무작위 분할 시 사용되는 난수 발생 seed 지정
- 중간에 바뀌지 않도록 seed 값 고정

stratify
- 클래스의 분포 유지
- binary set일 때만 가능한 건 아님.
