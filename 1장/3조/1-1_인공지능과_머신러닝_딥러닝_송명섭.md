마크다운
- ##으로 시작
- 내부적으로 기능 구현이 되어 있어 구동되는 것이 아닌, 직접 작성하는 것
- 마크업 언어의 일부
- 코드가 일반적인 소스 코드라면 텍스트는 마크다운 언어로 표현된 코드 


numpy를 통해 리스트가 아닌 배열을 사용하는 이유에는 효율성에 있다. 


분류와 회귀
- 대표적인 지도 학습
- 도출 결과: 이산적 vs 연속적


딥러닝을 위한 norm, 벡터의 길이 측정 방법은 2가지가 있다.
- 멘하튼 : 절댓값의 합(도시명에서 유래, 직선 거리 x), one norm(|)
- 유클리드 : 제곱합의 제곱근(일반적인 직선 거리), two norm(||)



변수가 다양하다면 엄밀히 구분하기 어려움
- knn에서 k는 홀수(만약 짝수라면 동률 발생 가능)
- k값이 작을수록 좋을 수 있긴함.


비선형은 말 그대로 선형이 아닌 것, 비선형이 곡면 또는 곡선 형태인 것만은 아님
머신러닝은 통계 기반이다. 선형적 패턴
비선형적이면 하나로 설명하기 어려워짐 
(ex.키와 몸무게 1cm 늘면 3kg 는다. 딥러닝은 키 하나만으로 설명하기 어려움)


2차원 리스트를 의미하는 표현은 리스트의 리스트 외에도 matrix, tensor(딥러닝 프레임워크에서 상용됨) 등 다양함.
 
tip. 간단한 의미 파악에는 블로그 글이 많지만 엄밀히 정의된 세부 내용은 공식 사이트에서 찾도록 하자. (ex. 사이킷런)
tip. 사이킷런에서 제공하는 모델 학습 메소드인 fit() 외에도 transform(), fit_transform()을 알아두자.

숫자로 변환 - 스케일러


score() 정확도 
-정확도만 가지고 판단하면 안 된다.
- 고려 사항은 민감도, 특이도 등 다양
- 알다시피 이 연산들은 베이즈 정리를 기반으로 한다. 당연하지만 AI수학에서 괜히 학습하는 게 아님.

샘플링 편향 or 불균형
- 교안처럼 데이터 접근하면 비효율적. index로 접근하기 어려움
- 마찬가지로 사이킷런에서 제공하는 좋은 게 있음, train_test_split()

stratify()
-전체 데이터의 비율 그대로 반영
- 모수의 비율을 똑같이 반영
- ex) 데이터가 7대3 비율 -> 테스트도 7대3

그 외
feature와 parameter는 상이하다.
hyper parameter와 parameter가 상이한 개념임을 알아두자. 
data leakage in Training, Validation, Test
