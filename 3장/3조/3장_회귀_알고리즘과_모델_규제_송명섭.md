I. bias  VS  var

(하단은 예전에 써둔 것인데 연결되는 내용이면서 상기시킬 겸 추가로 적은 입문 개념)

가로축 - 입력,x,특징(피처)
세로축 - 목푯값, y

ex) 공부시간 x와 성적 y의 경우 특징이 하나이나, 보통 2개 이상의 특징으로 구성된 특징 벡터 형태
(tmi. 그래서 스칼라 기호 x가 아닌 벡터 기호 x를 씀.)

(특징벡터, 목푯값) 쌍은 기계학습에 주어지는 데이터 : 훈련집합(학습집합)
훈련집합의 요소 : 샘플

훈련집합: X = {x1, x2, ... ,xn} , Y = {y1, y2, ... , yn}

직선형 모델은 y= wx +b 로 표현됨.(w,b는 매개변수)

학습(훈련) : 성능이 개선되며 최적의 상태에 도달하는 작업
테스트(test) : 훈련집합에 없는 '새로운' 샘플에 대한 목푯값을 예측하는 과정



다차원의 특징 공간

d차원의 데이터 : x = (x1,x2,...xd)^T
54877개의 단어의 빈도 파악 -> 544877차원

특징 공간 변환 - 분류에 유리하도록 특징 공간 변환 가능
차원이 증가한다고 알고리즘이 바뀌어야 하진 않음.

데이터베이스 = 훈련집합 + 테스트집합


고차원의 데이터 가시화 : 차원 축소

선형회귀 - 직선 모델을 사용하여 회귀 문제를 해결하는 기계학습 알고리즘 
직선 모델이므로 추정할 매개변수는 w,b 2개이고,  묶어서 다음과 같이 표현함.
θ = (w,b)^T

at first, we don't know the optimized θ -> 난수 생성 : θ1
 θ1을 개선하여  θ2로, 또 개선하여  θ3, ..., 최종적으로 최적의  θ에 도달
이때 직선을 움직이는 일종의 원동력이 필요, 목적함수(비용함수)

(예측함수의 출력) - (목푯값) -> 오차

목적함수의 값이 준다는 것은 오차자 개선된다는 것

최적의  θ = argmin J( θ) -> 기계학습의 역할
목적함수 값이 작아지는 방향을 찾아 매개변수 값 조정 반복

p.43 분석적 방법 vs 수치적 방법

과소적합, 과대적합
선형 모델의 한계? 과소적합 발생 시, 고차원의 다항식을 사용하자.
y = wx + w0
y = w12x^12 + w11x^11 + ... +  w2x^2 + w1x + w0 (12차원. 1차 미분 시 극점이 최대 11개인 대용량 모델)

 교재의 선형 다항식과 12차원 다항식 비교 시, 후자의 비선형이 완벽에 가깝게 '학습'을 함.
하지만 (학습이 아닌)'예측'을 해야 한다면 평가가 다름. 예측 값은 합리적인 범위 내에서 이루어져야 함.
-> 부적절한 이유는 용량이 매우 크기 때문이다.
-> 데이터 분포에 비해 너무나 대용량, 미세 잡음까지 반영해버림.(overfitting, low bias, high var)


기계학습의 목표는 훈련집합에 없는 새로운 샘플을 정확히 예측함에 있다.
다시 말해, 테스트 집합에 대한 고성능을 보장하는 프로그램을 만드는 것(일반화)

일반화를 위해 알아둘 것 -> bias, var(이 둘은 trade-off 관계)
Bias
-치우친 정도/ 출력과 정답 간 차이의 정도(머신러닝) 
Var
-퍼져있는 정도 /모델 예측의 가변성(머신러닝) 


Overfitting(상단의 고차원 방정식 연상)
- low bias, high var
Underfitting(저차원의 단순한 모델 복잡도, 적은 feature)
- high bias, low var
- feature를 더 많이 반영하여 var 높이기(활용 모델: kNN, SVM,...)


훈련집합으로 모델 학습, 테스트집합으로 일반화 능력 측정
-> 그렇다면, 좋은 모델을 찾기 위해 여러 모델 간 비교를 하는 방법은?

모델 선택 알고리즘 - 검증집합, 교차검증, 부트스트랩


II. Validation

먼저 이해할 것은 '데이터셋의 분리', 왜 데이터를 train, test 외에 valid까지 구분하는가? 

예측할 데이터를 모델에 적용하기 전에 모델 학습이 선행되어야 함. 모델 구현에 필요한 건 학습 데이터
모델을 평가하는 데 쓰이는 건 테스트 데이터
모델을 '검증'하는 데 쓰이는 게 validation set(검증을 통해 모델 성능 개선. 파라미터 튜닝도 한 과정)

평가와 검증을 분리해서 생각할 것
- 모델 검증에 쓰인 데이터를 모델 평가에 사용 시 높은 점수를 얻는 것은 trivial(지난 시간의 Data Leakage 연상)
- 계수 조정은 train에서, val은 변경 없이 검증만

Then, how to make the Validation Set?
1. 전체 데이터셋을 train과 test로 구분(보통 7:3 or 8:2가 보편적)
2. train set을 다시 train과 validation으로 구분

Warning) 전체 데이터가 너무 적다면 train_test_split과 ramdom_state의 매개변수를 조금만 조정해도 성능 평가
차이가 큼. 이때 교차검증 활용 가능

관련 메소드 : train_test_split()

train과 test로 분리할 때, train을 train과 test로 분리할 때의 두 가지 경우 모두 사용
해당 메소드 내에 parameter가 많은데, 이 중에서

random_state
- 무작위 분할 시 사용되는 난수 발생 seed 지정
- 중간에 바뀌지 않도록 seed 값 고정

stratify
- 클래스의 분포 유지
- binary set일 때만 가능한 건 아님.
