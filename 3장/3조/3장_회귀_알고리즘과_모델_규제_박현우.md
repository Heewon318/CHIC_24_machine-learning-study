### <두 번째 스터디 – 2024.01.19> 
### 범위: p.87~p.129
- 질의응답 중심으로 스터디를 진행하였습니다.
### Chapter 3 회귀 알고리즘과 모델 규제
##### 1. 회귀 알고리즘?(p.115)
- 회귀는 두 변수(독립변수)사이의 상관관계를 분석하는 방법 -> 종속변수를 찾는 과정
- 변수간의 상관관계를 파악하기 위해 사용 
- 선형회귀는 변수간 독립성을 가정하고 사용하는 것. 독립성이 보장되지 않으면 당연히 선형회귀 결과는 잘 나올 것
※ 다중공산성 PI CI VIF
##### 편향(bias)과 분산(variance)의 관계?
- trade off 하다:  (반비례는 아니지만..)
- 모델 예측 오차 vs 모델 예측 편차 
- low variance: 한 점에 몰려 있다
- bias: 영점 조절
- variance가 높으면 실력이 사격 실력이 안좋은 것. -> 딥러닝 : 할 때 마다 결과가 달라진다. -> variance가 높을 수 밖에 없다 (모델의 복잡성)
- bias가 높더라도 variance를 낮추려고 노력해야 한다.(물론 둘 다 낮으면 좋음)
- overfitting : variance가 높고 bias가 낮은 것. "일반화되지 못함"
- 딥러닝 같은 경우에 variance를 줄이기 위한 조치: parameter 줄이기, 가벼운 모델 쓰기 등등
###### 추가적인 내용은 추후 추가예정입니다.
